{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc81be1-0a0b-4058-a917-63e27695d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES AND PACKAGES\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659263dd-e1fc-4362-96cd-1f04295aaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARATION FOR SELENIUM\n",
    "url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=AAPL&datatype=csv&outputsize=compact&apikey=9YUPW0WRVEKUFF9L'\n",
    "df_stock = pd.read_csv(url)\n",
    "df_stock = df_stock.drop(columns=['volume'])\n",
    "df_stock.to_csv('stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6dce4d29-a761-4c7c-8bb9-62880cdeb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPEN DRIVER\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1909259-9cb8-4abc-bd9c-ebcd061213ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GO TO SENATOR TRADING PAGE\n",
    "url = \"https://trendspider.com/markets/congress-trading/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e23a971f-113f-4a6c-9433-844f98d7175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = driver.find_elements(By.CSS_SELECTOR, \"#main-content table thead th\")\n",
    "header_names = [header.text.strip() for header in headers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6d9f2326-4a60-4637-b611-7de08d9a5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE INFORMATION FROM THE FIRST PAGE\n",
    "data = []\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"#main-content table tbody tr\")\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    data.append([col.text.strip().replace('\\n', ' ') for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c319b3ae-2f9a-499b-8a48-b53bd7e69054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 809/809 [1:58:56<00:00,  8.82s/it]  \n"
     ]
    }
   ],
   "source": [
    "#GET THE INFORMATION FROM THE FIRST 811 PAGES (ORIGINAL DATASET)\n",
    "for i in tqdm(range(2, 811)):\n",
    "    check = f'[aria-label=\"Current Page, Page {i}.\"]'\n",
    "    site = f'[aria-label=\"Go to page {i}.\"]'\n",
    "    while driver.find_elements(By.CSS_SELECTOR, check) == []:\n",
    "        try:\n",
    "            driver.find_elements(By.CSS_SELECTOR, site)[0].click()\n",
    "        except Exception as e:\n",
    "            time.sleep(randint(10,20)/10)\n",
    "    \n",
    "\n",
    "    sleep(randint(10,20)/10)\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"#main-content table tbody tr\")\n",
    "    \n",
    "    sleep(randint(10,20)/10)\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        data.append([col.text.strip().replace('\\n', ' ') for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44d72557-6bd5-4618-814d-fd2359b01bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT COLUMN ABOUT TRANSACTIONS INTO 2 COLUMNS\n",
    "df = pd.DataFrame(data, columns=header_names)\n",
    "df[['Type', 'Amount']] = df['Transaction'].str.extract(r'(\\w+)\\s\\$(.*)')\n",
    "df = df.drop(columns=['Transaction', 'Excess return *'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "21175317-4657-4494-abce-6ef592572d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT AND QUITTING DRIVER\n",
    "#df.to_csv('senators_trading.csv', index=False) #DISABLED DUE TO POTENTIAL MISSCLICK\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84b31715-54a8-4b66-a4fd-1c6577ef92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('senators_trading.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541894b8",
   "metadata": {},
   "source": [
    "UPDATE (BOTH INFORMATION ABOUT ASSETS and ALSO SENATORS_TRADING DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "983e7dcc-ed0c-4b72-8e15-077ce0c5f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING THE CORE DATASET\n",
    "data_trading = pd.read_csv(\"senators_trading.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a931d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPEN DRIVER\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2892fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GO TO SENATORS TRADING WEBPAGE\n",
    "url = \"https://trendspider.com/markets/congress-trading/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2a12acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = driver.find_elements(By.CSS_SELECTOR, \"#main-content table thead th\")\n",
    "header_names = [header.text.strip() for header in headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abf5265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE DATA FROM THE FIRST PAGE\n",
    "data = []\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"#main-content table tbody tr\")\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    data.append([col.text.strip().replace('\\n', ' ') for col in cols])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=header_names)\n",
    "df[['Type', 'Amount']] = df['Transaction'].str.extract(r'(\\w+)\\s\\$(.*)')\n",
    "df = df.drop(columns=['Transaction', 'Excess return *'])\n",
    "\n",
    "#SAVE LAST ROW FROM THE TEMPORAL DATASET (WILL BE USED TO CHECK, IF ORIGINAL DATASET CONTAINS THE UPDATED DATA)\n",
    "last_note = df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d36a5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTINUE TO 2nd ... PAGE. CONITINUE UNTIL THE UPDATED DATASET STARTS TO INTERSECT WITH THE ORIGINAL DATASET\n",
    "i = 2\n",
    "while ((data_trading == last_note).all(axis=1)).any() == False:\n",
    "    data = []\n",
    "    check = f'[aria-label=\"Current Page, Page {i}.\"]'\n",
    "    site = f'[aria-label=\"Go to page {i}.\"]'\n",
    "    while driver.find_elements(By.CSS_SELECTOR, check) == []:\n",
    "        try:\n",
    "            driver.find_elements(By.CSS_SELECTOR, site)[0].click()\n",
    "        except Exception as e:\n",
    "            time.sleep(randint(10,20)/10)\n",
    "    sleep(randint(10,50)/10)\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"#main-content table tbody tr\")\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        data.append([col.text.strip().replace('\\n', ' ') for col in cols])\n",
    "\n",
    "    help_df = pd.DataFrame(data, columns=header_names)\n",
    "    help_df[['Type', 'Amount']] = help_df['Transaction'].str.extract(r'(\\w+)\\s\\$(.*)')\n",
    "    help_df = help_df.drop(columns=['Transaction', 'Excess return *'])\n",
    "\n",
    "    df = pd.concat([df, help_df])\n",
    "\n",
    "\n",
    "    i += 1\n",
    "    last_note = df.iloc[-1]\n",
    "\n",
    "    print(last_note)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#LEAVE ONLY RECORDS FROM TEMPORAL DATASET, WHICH ARE NOT IN THE ORIGINAL DATASET (CANNOT USE DROP_DUPLICATES DUE TO SIMILARITY BETWEEN SOME TRADES)\n",
    "mask = ~df.apply(tuple, axis=1).isin(data_trading.apply(tuple, axis=1))\n",
    "result = df[mask]\n",
    "\n",
    "#SAVE THE ORIGINAL SYMBOLS FROM THE ORIGINAL CORE DATASET (WHICH CORRESPOND TO THE ORIGINAL DATASET WITH INFO ABOUT STOCKS,ETF,MUTUAL FUNDS...)\n",
    "original_symbols = data_trading.Stock.apply(lambda x: x.split(\" \")[0]).drop_duplicates()\n",
    "\n",
    "#CONNECT TEMPORAL AND CORE DATASET TO GET UP TO DATE DATASET\n",
    "data_trading = pd.concat([result, data_trading])\n",
    "\n",
    "#ADD SYMBOLS TO DATASET\n",
    "data_trading[\"ABR\"] = data_trading.Stock.apply(lambda x: x.split(\" \")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5051a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dario Mikuš\\AppData\\Local\\Temp\\ipykernel_17248\\80750706.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result[\"ABR\"] = result.Stock.apply(lambda x: x.split(\" \")[0])\n"
     ]
    }
   ],
   "source": [
    "#GET THE SYMBOLS FROM THE TEMPORAL DATASET AND LEAVE ONLY THOSE ETH,STOCKS..., FOR WHICH THE INFORMATION ARE MISSING\n",
    "result[\"ABR\"] = result.Stock.apply(lambda x: x.split(\" \")[0])\n",
    "result_symbols = result.ABR.drop_duplicates()\n",
    "\n",
    "additional_symbols = ~result_symbols.isin(original_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3b592b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#ITTER THROUGH SYMBOLS WITHOUT INFORMATION TO OBTAIN MISSING INFORMATION FROM YAHOO_FINANCE\n",
    "#MUST CREATE SEVERAL DATASETS DUE TO DIFFERENCES BETWEEN THE ASSET TYPES\n",
    "equity = pd.DataFrame()\n",
    "mutual_fund = pd.DataFrame()\n",
    "etf = pd.DataFrame()\n",
    "other = pd.DataFrame()\n",
    "\n",
    "# ITERATE THROUGH SYMBOLS AND GAIN MISSING INFORMATION\n",
    "for symbol in tqdm(additional_symbols):\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        time.sleep(randint(10,20)/10)\n",
    "\n",
    "        stock_info = pd.json_normalize(stock.info)\n",
    "\n",
    "        if 'quoteType' in stock_info.columns:\n",
    "            quote_type = stock_info['quoteType'][0]\n",
    "        \n",
    "    \n",
    "            if quote_type == 'ETF':\n",
    "                etf = pd.concat([etf, stock_info], ignore_index=True)\n",
    "            elif quote_type == 'EQUITY':\n",
    "                equity = pd.concat([equity, stock_info], ignore_index=True)\n",
    "            elif quote_type == 'MUTUALFUND':\n",
    "                mutual_fund = pd.concat([mutual_fund, stock_info], ignore_index=True)\n",
    "            else:\n",
    "                other = pd.concat([other, stock_info], ignore_index=True)\n",
    "        else:\n",
    "             print(f\"quoteType not found for {symbol}. Skipping.\")\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19886c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATASET\n",
    "info_dataset = pd.read_csv(\"info_dataset.csv\")\n",
    "\n",
    "#ETF\n",
    "try:\n",
    "    data_etf = etf[[\"quoteType\", \"symbol\", \"category\", \"currency\"]]\n",
    "except:\n",
    "    data_etf = pd.DataFrame(columns = [\"quoteType\", \"symbol\", \"category\", \"currency\"])\n",
    "\n",
    "#EQUITY\n",
    "try:\n",
    "    data_equity = equity[[\"quoteType\", \"symbol\", \"country\", \"industry\", \"sector\", \"financialCurrency\"]]\n",
    "\n",
    "    data_equity = data_equity.rename(columns = {\"industry\" : \"category\", \"financialCurrency\" : \"currency\"})\n",
    "except:\n",
    "    data_equity = pd.DataFrame(columns = [\"quoteType\", \"symbol\", \"country\", \"industry\", \"sector\", \"financialCurrency\"])\n",
    "\n",
    "\n",
    "#MUTUAL FUND\n",
    "try:\n",
    "    data_mutual_fund = mutual_fund[[\"quoteType\", \"symbol\", \"currency\"]]\n",
    "except:\n",
    "    data_mutual_fund = pd.DataFrame(columns = [\"quoteType\", \"symbol\", \"currency\"])\n",
    "\n",
    "#OTHER\n",
    "try:\n",
    "    data_other = other[[\"quoteType\", \"symbol\", \"currency\"]]\n",
    "except:\n",
    "    data_other = pd.DataFrame(columns = [\"quoteType\", \"symbol\", \"currency\"])\n",
    "\n",
    "#MERGE ALL DATASETS TO GET UP TO DATE DATASET WITH INFORMATION ABOUT ASSETS\n",
    "info_dataset = pd.concat([info_dataset, data_etf, data_equity, data_mutual_fund, data_other], ignore_index=True, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82afc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f41ee6",
   "metadata": {},
   "source": [
    "GETTING INFO ABOUT STOCKS_ETF_FUNDS... (CORE DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3048dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE SYMBOLS, TO BE USED IN YAHOO_FINANCE API\n",
    "data_trading[\"ABR\"] = data_trading.Stock.apply(lambda x: x.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0be0b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAIN UNIQUE SYMBOLS\n",
    "symbols = data_trading.ABR.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f8c0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE EMPTY DATASETS DUE TO DIFFERENCES BETWEEN INFORMATION PROVIDED FOR DIFFERENT ASSETS\n",
    "equity = pd.DataFrame()\n",
    "mutual_fund = pd.DataFrame()\n",
    "etf = pd.DataFrame()\n",
    "other = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5db758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATE THROUGH ALL SYMBOLS\n",
    "for symbol in tqdm(symbols):\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        time.sleep(randint(10,20)/10)\n",
    "\n",
    "        stock_info = pd.json_normalize(stock.info)\n",
    "\n",
    "        if 'quoteType' in stock_info.columns:\n",
    "            quote_type = stock_info['quoteType'][0]\n",
    "        \n",
    "    \n",
    "            if quote_type == 'ETF':\n",
    "                etf = pd.concat([etf, stock_info], ignore_index=True)\n",
    "            elif quote_type == 'EQUITY':\n",
    "                equity = pd.concat([equity, stock_info], ignore_index=True)\n",
    "            elif quote_type == 'MUTUALFUND':\n",
    "                mutual_fund = pd.concat([mutual_fund, stock_info], ignore_index=True)\n",
    "            else:\n",
    "                other = pd.concat([other, stock_info], ignore_index=True)\n",
    "        else:\n",
    "             print(f\"quoteType not found for {symbol}. Skipping.\")\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64cffade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT (NO LONGER USED)\n",
    "#other.to_csv(\"other.csv\")\n",
    "#etf.to_csv(\"etf.csv\")\n",
    "#equity.to_csv(\"equity.csv\")\n",
    "#mutual_fund.to_csv(\"mutual_fund.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb8f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD (NO LONGER USED DUE TO CREATION OF OVERAL DATASET)\n",
    "other = pd.read_csv(\"other.csv\")\n",
    "equity = pd.read_csv(\"equity.csv\")\n",
    "mutual_fund = pd.read_csv(\"mutual_fund.csv\")\n",
    "etf = pd.read_csv(\"etf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ebccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMATIVE DATA FOR ETF\n",
    "data_etf = etf[[\"quoteType\", \"symbol\", \"category\", \"currency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2206483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMATIVE DATA FOR EQUITY\n",
    "data_equity = equity[[\"quoteType\", \"symbol\", \"country\", \"industry\", \"sector\", \"financialCurrency\"]]\n",
    "\n",
    "data_equity = data_equity.rename(columns = {\"industry\" : \"category\", \"financialCurrency\" : \"currency\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMATIVE DATA FOR MUTUAL FUNDS\n",
    "data_mutual_fund = mutual_fund[[\"quoteType\", \"symbol\", \"currency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMATIVE DATA FOR OTHER TYPES (INDEX, NONE)\n",
    "data_other = other[[\"quoteType\", \"symbol\", \"currency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3c7f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE COMPLET INFO DATASET\n",
    "info_dataset = pd.DataFrame(columns= [\"symbol\", \"quoteType\", \"country\", \"category\", \"sector\", \"currency\", \"category\"])\n",
    "\n",
    "info_dataset = pd.concat([data_etf, data_equity, data_mutual_fund, data_other], ignore_index=True, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT\n",
    "info_dataset.to_csv(\"info_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
